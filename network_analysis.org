#+PROPERTY: header-args:jupyter-python  :session py
#+PROPERTY: header-args    :pandoc t

* The weighted k-shell decomposition method

Here we propose a generalization of the k-shell decomposition method, which we call the weighted k-shell decomposition method (Wk-shell). This method applies the same pruning routine that was described earlier, but is based on an alternative measure for the node degree. This measure considers both the degree of a node and the weights of its links, and we assign for each node a weighted degree, k'. The weighted degree of a node i is defined as $k'_{i}=\sqrt {k_{i} \sum _{j}^{k_{i}}{w_{ij}}}$ .

Using the above approach in the case of unweighted networks, where $w_{ij} = 1$, the weighted degree is equivalent to the node degree (k' ≡ k), and we resume the same network partitioning as with the Uk-shell decomposition method. However, in order that a typical weighted link be regarded as of unit weight before we calculate k' using equation (1), we perform the following steps. First, we normalize all the weights with their mean value 〈w〉, next we divide the resulting weights with their minimum value, and we discretize them by rounding to the closest integer; this way the minimum link weight is equal to 1

Here's what that means in code:
#+begin_src jupyter-python
  def weighted_degree(node):
      degree = node.degree()
      edge_weights = [edge.weight for edge in node.edges()]
      return np.sqrt(degree * np.sum(edge_weights))

#+end_src
The [[https://networkx.org/documentation/stable/][networkx]] library offers a lot of nice functions for working with graphs, including the unweighted k-shell decomposition method. Unfortunately, there's no option there for adding weights yet.

That said, here's their function for calculating the coreness of each vertex:
#+begin_src jupyter-python
  def core_number(G):
      degrees = dict(G.degree())
      # Sort nodes by degree.
      nodes = sorted(degrees, key=degrees.get)
      bin_boundaries = [0]
      curr_degree = 0

      # Mark where each degree changes, including if it changes by more than one
      for i, v in enumerate(nodes):
          if degrees[v] > curr_degree:
              bin_boundaries.extend([i] * (degrees[v] - curr_degree))
              curr_degree = degrees[v]

      # This is a bit redundant given that we've sorted the nodes already... I
      # think it's so that we can iterate over the nodes and reorder them at the
      # same time
      node_pos = {v: pos for pos, v in enumerate(nodes)}
      # The initial guess for the core number of a node is its degree.
      core = degrees
      neighbors = {v: list(nx.all_neighbors(G, v)) for v in G}
      # I think this should have been an iteration over indices in the graph
      # rather than anything else. I'll try an code it again to see what happens
      for v in nodes:
          for u in neighbors[v]:
              # If the neighbor is more central than us:
              if core[u] > core[v]:
                  # Remove this node from the neighborlist of the other one
                  neighbors[u].remove(v)
                  # Move the other node to the start of its bin by swapping it
                  # with whatever was at the start of the bin previously
                  pos = node_pos[u]
                  bin_start = bin_boundaries[core[u]]
                  node_pos[u] = bin_start
                  node_pos[nodes[bin_start]] = pos
                  nodes[bin_start], nodes[pos] = nodes[pos], nodes[bin_start]
                  # Move the bin boundary up by one, so that "u" is now the last
                  # node of degree n - 1
                  bin_boundaries[core[u]] += 1
                  # And update the corresponding degree in u
                  core[u] -= 1
      return core
#+end_src

Making it work with weighted graphs requires a bit of thought. All references to `degree` can be changed to `weighted_degree`, but the line `core[u] -= 1` needs a bit of rejiggering, since it needs to be converted to a recalculation of what the weighted degree would be if we removed v as a neighbor of u.

If we have a node $i$, with neighbours $\{j\}$ and remove $\alpha \in \{j\}$, the difference becomes as follows:

\begin{align}
\Delta^2
  &\equiv k'_{\mathrm{big}}^2 - k'_{\mathrm{small}}^2 \\
  &= \sum_{ij} w_{ij} + (k_i - 1)w_{\alpha i}
\end{align}
As as sanity check, if all the $w_{ij} = 1$, we have
$$
\Delta^2 = k_i + k_i - 1 = 2k_i - 1,
$$
which is exactly the difference between neighbouring square numbers.

Unfortunately, this means that the update function cannot just take a weighted degree and the weight of an edge as input, since the same weighted degree could be achieved in different ways, and would be dependent on the real degree/real set of edges anyway. We need to keep track of that information somehow.

We can look at the pseudo-code from this [[https://arxiv.org/abs/cs/0310049][paper]], and replace each instance of "degree" with "weighted degree"

1.1 compute the degrees of vertices;
1.2 order the set of vertices V in increasing order of their degrees;
2 for each v ∈ V in the order do begin
2.1 core[v] := degree[v];
2.2 for each u ∈ Neighbors(v) do
2.2.1 if degree[u] > degree[v] then begin
2.2.1.1 degree[u] := calculate_weighted_degree(u);
2.2.1.2 reorder V accordingly
end
end;

#+begin_src jupyter-python
  import bisect
  import math
  
  def weighted_core_number(G):
      core = calculate_weighted_degrees(G)
      nodes = sorted(G, key=weighted_degree)
      neighbors = {v: list(nx.all_neighbors(G, v)) for v in G}
      for i in range(len(nodes)):
          v = nodes[i]
          for u in neighbors[v]:
              if core[u] > core[v]:
                  neighbors[u].remove[v]
                  old_position = bisect.bisect(nodes, core[u])
                  core[u] = weighted_degree(neighbors[u])
                  new_position = bisect.bisect(nodes, core[u])
                  del nodes[old_position]
                  nodes.insert(new_position, u)
      return core
  
#+end_src


** Playing with networkx
Before we get that far, we might try to play around with the networkx library, and see what sort of functionality it offers out of the box
#+begin_src jupyter-python
  import networkx as nx
  import csv
  G = nx.DiGraph()
  edges = []
  with open('graph_1000.csv', 'r', newline='') as f:
      reader = csv.DictReader(f)
      for row in reader:
          edges.append([row['Source'], row['Target'], row['Weight']])
  G.add_weighted_edges_from(edges)
  G.remove_edges_from(nx.selfloop_edges(G))
#+end_src

#+RESULTS:

#+begin_src jupyter-python
  from networkx.algorithms.core import core_number
  
  core = core_number(G)

#+end_src
#+RESULTS:
#+begin_src jupyter-python
  import numpy as np
  frame = pd.DataFrame(edges, columns=["Source", "Target", "Weight"])
  frame.set_index("Source", inplace=True)
  frame['Weight'] = frame['Weight'].astype(int)
  frame['Weight'] = 1 + np.log10(frame['Weight'])
#+end_src

#+RESULTS:

* The onion decomposition
https://www.nature.com/articles/srep31708

Idea: make a k-shell decomposition (recursively remove nodes of degree <= k from the graph until there are no more, then do the same for k+1), but keep track of which/how nodes are removed for each pass *within* a shell, and not just what the k value is.

